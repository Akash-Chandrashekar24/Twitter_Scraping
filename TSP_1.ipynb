{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTTEX9fr5kGE",
        "outputId": "6265cb4d-8155-4eba-cdae-ae75913f5e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-06-12 17:17:42.588 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# importing libraries and modules needed for the project\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from datetime import date\n",
        "\n",
        "# twitter scraping image,Titles and sub-heading\n",
        "img = Image.open('Twitter-scraping.jpg')\n",
        "st.image(img)\n",
        "st.subheader(\"Scrape Tweets with any keywords or Hashtag as you wish!\")\n",
        "st.sidebar.title(\"**:blue[:wave: Hello there!!!]**\")\n",
        "st.sidebar.header(\"**:blue[Kindly fill the below details to begin Scraping Tweets] :point_down:**\")\n",
        "\n",
        "# Variable declaration for user inputs(Keyword and Number of tweets)\n",
        "hashtag = st.sidebar.text_input(\"Enter the keyword or Hashtag you need to get : \")\n",
        "tweets_count = st.sidebar.number_input(\"Enter the number of Tweets to Scrape : \", min_value= 1, max_value= 1000, step= 1)\n",
        "st.sidebar.subheader(\":blue[Select the date range] :calendar:\")\n",
        "start_date = st.sidebar.date_input(\"Start date (YYYY-MM-DD) : \")\n",
        "end_date = st.sidebar.date_input(\"End date (YYYY-MM-DD) : \")\n",
        "today = str(date.today())\n",
        "\n",
        "# Creating an empty list\n",
        "tweets_list = []\n",
        "# Enabling the Checkbox only when the hashtag is entered\n",
        "if hashtag:\n",
        "    st.sidebar.checkbox(\"**Scrape Tweets**\")\n",
        "\n",
        "    # Using for loop, TwitterSearchScraper and enumerate function to scrape data and append tweets to list\n",
        "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{hashtag} since:{start_date} until:{end_date}').get_items()):\n",
        "        if i >= tweets_count:\n",
        "            break\n",
        "        tweets_list.append([tweet.date,\n",
        "                            tweet.id,\n",
        "                            tweet.url,\n",
        "                            tweet.rawContent,\n",
        "                            tweet.user.username,\n",
        "                            tweet.replyCount,\n",
        "                            tweet.retweetCount,\n",
        "                            tweet.likeCount,\n",
        "                            tweet.lang,\n",
        "                            tweet.source\n",
        "                           ])\n",
        "else:\n",
        "    st.sidebar.checkbox(\"**Scrape Tweets**\",disabled=True)\n",
        "\n",
        "# Creating DataFrame with the scraped tweets\n",
        "def data_frame(data):\n",
        "    return pd.DataFrame(data, columns= ['datetime', 'user_id', 'url', 'tweet_content', 'user_name',\n",
        "                                         'reply_count', 'retweet_count', 'like_count', 'language', 'source'])\n",
        "\n",
        "# Converting DataFrame to CSV file\n",
        "def convert_to_csv(c):\n",
        "    return c.to_csv().encode('utf-8')\n",
        "\n",
        "# Converting DataFrame to JSON file\n",
        "def convert_to_json(j):\n",
        "    return j.to_json(orient='index')\n",
        "\n",
        "# Creating objects for dataframe and file conversion\n",
        "df = data_frame(tweets_list)\n",
        "csv = convert_to_csv(df)\n",
        "json = convert_to_json(df)\n",
        "\n",
        "# Bridging a connection with MongoDB Atlas and Creating a new database(twitterscraping) and collections(scraped_data)\n",
        "client = pymongo.MongoClient(\"mongodb+srv://akashchandrashekar98:Amrita123@cluster0.bggdryh.mongodb.net/?retryWrites=true&w=majority\")\n",
        "db = client.twitterscraping\n",
        "col = db.scraped_data\n",
        "scr_data = {\"Scraped_word\" : hashtag,\n",
        "            \"Scraped_date\" : today,\n",
        "            \"Scraped_data\" : df.to_dict('records')\n",
        "           }\n",
        "\n",
        "# BUTTON 1 - To view the DataFrame\n",
        "if st.button(\"View DataFrame\"):\n",
        "    st.success(\"**:blue[DataFrame Fetched Successfully]**\", icon=\"âœ…\")\n",
        "    st.write(df)\n",
        "\n",
        "# BUTTON 2 - To upload the data to mongoDB database\n",
        "if st.button(\"Upload the data to MongoDB\"):\n",
        "    try:\n",
        "        col.delete_many({}) #Deleting old records from the collection\n",
        "        col.insert_one(scr_data)\n",
        "        st.success('Upload to MongoDB Successful!', icon=\"âœ…\")\n",
        "    except:\n",
        "        st.error('You cannot upload an empty dataset. Kindly enter the information in the leftside menu.', icon=\"ðŸš¨\")\n",
        "\n",
        "# Header Diff Options to download the dataframe\n",
        "st.subheader(\"**:blue[To download the data use the below buttons :arrow_down:]**\")\n",
        "\n",
        "# BUTTON 3 - To download data as CSV\n",
        "st.download_button(label= \"Download data as CSV\",\n",
        "                   data= csv,\n",
        "                   file_name= 'scraped_tweets_data.csv',\n",
        "                   mime= 'text/csv'\n",
        "                  )\n",
        "\n",
        "# BUTTON 4 - To download data as JSON\n",
        "st.download_button(label= \"Download data as JSON\",\n",
        "                   data= json,\n",
        "                   file_name= 'scraped_tweets_data.json',\n",
        "                   mime= 'text/csv'\n",
        "                  )"
      ]
    }
  ]
}